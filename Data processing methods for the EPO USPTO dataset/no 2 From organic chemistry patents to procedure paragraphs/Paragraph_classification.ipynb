{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "#from tqdm import tqdm\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"classification_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file='full_30k_3m.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT define the location and the appropriate slices for the location.\n",
    "directory_sorc = 'K:/US_applications/all_cleaned_modified/'\n",
    "listoffiles = glob(directory_sorc+\"*.csv\")\n",
    "print(listoffiles[0][40:-9])\n",
    "print(len(listoffiles))\n",
    "directory_sorc = 'K:/US_grants/all_cleaned_modified/'\n",
    "listoffiles2 = glob(directory_sorc+\"*.csv\")\n",
    "print(listoffiles2[-1][34:-9])\n",
    "print(len(listoffiles2))\n",
    "directory_sorc = 'K:/EU/EU_modified/'\n",
    "listoffiles3 = glob(directory_sorc+\"*.csv\")\n",
    "print(listoffiles3[0][18:-4])\n",
    "print(len(listoffiles3))\n",
    "listoffiles = listoffiles + listoffiles2  + listoffiles3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "start_num = 0\n",
    "\n",
    "for num_fil,file in enumerate(listoffiles):\n",
    "    #if num_fil < 11:\n",
    "        #continue\n",
    "    print(file)\n",
    "    PAT = []\n",
    "    YEAR = []\n",
    "    TYP = []\n",
    "    MOD = []\n",
    "    prev = []\n",
    "    collected = []\n",
    "    prob = []\n",
    "    nontype = False\n",
    "    X = []\n",
    "    if 'cleaned' in file[34:]:\n",
    "        nontype = True\n",
    "        data = pd.read_table(file, sep='\\t',header=0,names=[\"PatentNumber\",'PatentYear', \"Paragraph\",\"Modified\"],converters = {'PatentNumber' : str,'PatentYear' : str,'Paragraph':str,'Modified':int})\n",
    "    else:\n",
    "        data = pd.read_table(file, sep='\\t',header=0,names=[\"PatentNumber\",'PatentYear','PatentType', \"Paragraph\",\"Modified\"],converters = {'PatentNumber' : str,'PatentYear' : str,'Paragraph':str,'PatentType':str,'Modified':int})\n",
    "    datap=data.copy(deep=True)\n",
    "    data['totalwords'] = [len(x.split()) for x in data['Paragraph'].tolist()]\n",
    "    \n",
    "    data.dropna(subset=['Paragraph'],inplace=True)\n",
    "    data = data[data['totalwords'] < 500]\n",
    "    data = data[data['totalwords'] > 10]\n",
    "    data = data[data['Paragraph']!='']\n",
    "    del data['totalwords']\n",
    "    total_len = len(data)\n",
    "    print('total: ',len(data))\n",
    "    \n",
    "    data['TBR'] = 0\n",
    "\n",
    "    data['Paragraph_en'] = data['Paragraph'].apply(lambda x: sp.encode(x))\n",
    "    data['totalwords_en'] = [len(x) for x in data['Paragraph_en'].tolist()]\n",
    "    data = data[data['totalwords_en'] < 30000]\n",
    "\n",
    "    X = [np.array(fen,dtype=np.int32) for fen in data['Paragraph_en']]\n",
    "\n",
    "    print('to_rag')\n",
    "    X = tf.ragged.constant(X)\n",
    "    \n",
    "    y_pred = model.predict(X,verbose=1,batch_size=256)\n",
    "    \n",
    "    y_copy = y_pred.copy()\n",
    "    \n",
    "    y_pred[y_pred>=0.5] = 1\n",
    "    y_pred[y_pred<1-0.5] = 0\n",
    "    rez = []\n",
    "    rezf = []\n",
    "    for z in y_pred.tolist():\n",
    "        rez.append(int(z[0]))\n",
    "    for z in y_copy.tolist():\n",
    "        rezf.append(round(float(z[0]),3))\n",
    "    data['Predicted_2'] = rez\n",
    "    data['Predicted'] = rezf\n",
    "    data = data[data['Predicted_2']==1]\n",
    "    data['Paragraph'] = data['Paragraph'].str.replace('\\n','')\n",
    "    del data['Predicted_2']\n",
    "    #data.reset_index(drop=True,inplace=True)\n",
    "    for z in list(data.index):\n",
    "        start_num += 1\n",
    "        #if start_num in to_take:\n",
    "        if z != 0:\n",
    "            prev.append(datap.at[z-1,'Paragraph'])\n",
    "        \n",
    "        collected.append(data.at[z,'Paragraph'])\n",
    "        PAT.append(data.at[z,'PatentNumber'])\n",
    "        YEAR.append(data.at[z,'PatentYear'])\n",
    "        MOD.append(data.at[z,'Modified'])\n",
    "        #MOD.append(data.at[z,'Modified'])\n",
    "        prob.append(data.at[z,'Predicted'])\n",
    "        if nontype == True:\n",
    "            TYP.append('unknown')\n",
    "        else:\n",
    "            TYP.append(data.at[z,'PatentType'])\n",
    "            \n",
    "    dicte = {'PatentNumber': PAT, 'PatentYear': YEAR,'PatentType':TYP, 'Paragraph': collected,'Modified':MOD,'Predicted':prob,'PreviousP':prev}\n",
    "    df = pd.DataFrame(dicte,columns =['PatentNumber','PatentYear','PatentType','Paragraph','PreviousP','Modified','Predicted'])\n",
    "    if num_fil < 22:\n",
    "        print('applic: ',start_num, round(start_num/total_len,2))\n",
    "        df.to_csv('K:/Full_run/applic_'+listoffiles[num_fil][40:-9]+'.csv',sep='\\t',index=False)\n",
    "    if 21 < num_fil < 74:\n",
    "        print('grants: ',start_num, round(start_num/total_len,2))\n",
    "        df.to_csv('K:/Full_run/grants_'+listoffiles[num_fil][34:-9]+'.csv',sep='\\t',index=False)\n",
    "    if 73 < num_fil:\n",
    "        print('EU: ',start_num, round(start_num/total_len,2))\n",
    "        df.to_csv('K:/Full_run/EU_pat_'+listoffiles[num_fil][18:-4]+'.csv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
