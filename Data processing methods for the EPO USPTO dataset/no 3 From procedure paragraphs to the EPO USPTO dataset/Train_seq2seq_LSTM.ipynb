{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "#Train the tokenizer if needed.\n",
    "\n",
    "#spm.SentencePieceTrainer.train(input='all_classified_paragraphs_text.txt' , model_prefix='FIN_P2A_32k',split_digits=True, train_extremely_large_corpus=False, vocab_size=32000,input_sentence_size=5000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "import numpy as np\n",
    "import time, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding,Bidirectional,Concatenate,Flatten\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras.initializers import *\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_input = spm.SentencePieceProcessor(model_file='FIN_P2A_8k.model')\n",
    "sp_tgt = spm.SentencePieceProcessor(model_file='FIN_P2A_8k.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use training data\n",
    "\n",
    "train_raw_loc = 'src-train.txt'\n",
    "target_raw_loc = 'tgt-train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_raw_loc, 'r', encoding='utf-8') as f:\n",
    "    train_raw_lines = f.read().split('\\n')\n",
    "    train_raw_lines = train_raw_lines[:-1]\n",
    "with open(target_raw_loc, 'r', encoding='utf-8') as f:\n",
    "    target_raw_lines = f.read().split('\\n')\n",
    "    target_raw_lines = target_raw_lines[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the data for testing\n",
    "#train_raw_lines = train_raw_lines[:8000]\n",
    "#target_raw_lines = target_raw_lines[:8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C-Pyrazin-2-yl-methylamine 1h (10.9 g, 100 mmol) was added into a reaction flask, then 20 mL of trifluoroacetic anhydride was added dropwise slowly within an hour at 0° C. in an ice-water bath.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADD C-Pyrazin-2-yl-methylamine 1h (10.9 g, 100 mmol); ADD trifluoroacetic anhydride (20 mL) dropwise at 0° C over an hour.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_raw_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_in_data = []\n",
    "decoder_in_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max dec len: 128\n",
      "max enc len: 360\n"
     ]
    }
   ],
   "source": [
    "#Define man enc and dec limits\n",
    "\n",
    "for p,one_in in enumerate(target_raw_lines):\n",
    "    sptgt = sp_tgt.encode(one_in)\n",
    "    if len(sptgt)>128:\n",
    "        continue\n",
    "    decoder_in_data.append(sptgt)\n",
    "    encoder_in_data.append(sp_input.encode(train_raw_lines[p]))\n",
    "max_dencoder_seq_length = max([len(txt) for txt in decoder_in_data])\n",
    "print('max dec len:',max_dencoder_seq_length)\n",
    "\n",
    "max_encoder_seq_length = max([len(txt) for txt in encoder_in_data])\n",
    "print('max enc len:',max_encoder_seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15464"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder_in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_in_data_p = np.zeros((len(train_raw_lines), max_encoder_seq_length), dtype='int')\n",
    "decoder_in_data_p = np.zeros((len(encoder_in_data), max_dencoder_seq_length+1), dtype='int')\n",
    "decoder_target_data_p = np.zeros((len(encoder_in_data), 8000), dtype='int')\n",
    "\n",
    "encoder_in_data_p = tf.ragged.constant(encoder_in_data)\n",
    "\n",
    "\n",
    "decoder_in_data_r = []\n",
    "for nu, current_tgt in enumerate(decoder_in_data):\n",
    "    decoder_in_data_r.append([2])\n",
    "    for word_idx, word_id in enumerate(current_tgt):\n",
    "        decoder_in_data_r[nu].append(word_id)\n",
    "        decoder_in_data_p[nu][0] = 2\n",
    "        \n",
    "        decoder_in_data_p[nu][word_idx+1] = word_id\n",
    "        decoder_target_data_p[nu][word_id] = 1\n",
    "\n",
    "decoder_in_data_r = tf.ragged.constant(decoder_in_data_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15464, None)\n",
      "(15464, None)\n",
      "(15464, 8000)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_in_data_p.shape)\n",
    "print(decoder_in_data_r.shape)\n",
    "print(decoder_target_data_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "decoder_target_data_p[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 32\n",
    "num_encoder_tokens = 8001\n",
    "num_decoder_tokens = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb = Embedding(num_encoder_tokens, latent_dim)\n",
    "encoder = LSTM(int(latent_dim), return_state=True)\n",
    "\n",
    "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder(enc_emb(encoder_inputs))\n",
    "\n",
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb = Embedding(num_decoder_tokens, latent_dim,)\n",
    "\n",
    "decoder_lstm = LSTM(int(latent_dim), return_sequences=False, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb(decoder_inputs),\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_15 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_10 (Embedding)       (None, None, 32)     256032      ['input_15[0][0]']               \n",
      "                                                                                                  \n",
      " input_16 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " bidirectional_5 (Bidirectional  [(None, 32),        6272        ['embedding_10[0][0]']           \n",
      " )                               (None, 16),                                                      \n",
      "                                 (None, 16),                                                      \n",
      "                                 (None, 16),                                                      \n",
      "                                 (None, 16)]                                                      \n",
      "                                                                                                  \n",
      " embedding_11 (Embedding)       (None, None, 32)     256000      ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 32)           0           ['bidirectional_5[0][1]',        \n",
      "                                                                  'bidirectional_5[0][3]']        \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 32)           0           ['bidirectional_5[0][2]',        \n",
      "                                                                  'bidirectional_5[0][4]']        \n",
      "                                                                                                  \n",
      " lstm_11 (LSTM)                 [(None, 32),         8320        ['embedding_11[0][0]',           \n",
      "                                 (None, 32),                      'concatenate_10[0][0]',         \n",
      "                                 (None, 32)]                      'concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 8000)         264000      ['lstm_11[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 790,624\n",
      "Trainable params: 790,624\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit([encoder_in_data_p, decoder_in_data_p], decoder_target_data_p, batch_size = 32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    dec_emb(decoder_inputs), initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "     \n",
    "    \n",
    "    input_seq = sp_input.encode(input_seq)\n",
    "\n",
    "    \n",
    "    states_value = encoder_model.predict([input_seq])\n",
    "\n",
    "    target_seq = np.zeros((1, 1))\n",
    "\n",
    "    target_seq[0] = [2]\n",
    "\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    decoded_sentence_is = []\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "        #print(output_tokens[0, -1, :])\n",
    "        # Sample a token\n",
    "        print(output_tokens)\n",
    "        sampled_token_index = np.argmax(output_tokens[0])\n",
    "        decoded_sentence_is.append(int(sampled_token_index))\n",
    "        \n",
    "        sampled_char = sp_tgt.decode([int(sampled_token_index)])\n",
    "        \n",
    "        decoded_sentence += sampled_char\n",
    "        print(decoded_sentence)\n",
    "\n",
    "        if (sampled_token_index == 3 or\n",
    "           len(decoded_sentence_is) > 37):\n",
    "            stop_condition = True\n",
    "\n",
    "\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0] = [sampled_token_index]\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return sp_tgt.decode(decoded_sentence_is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_sequence('The residue was purified by flash chromatography (1% to 100% EtOAc/Hexanes) to afford methyl 4-(phenylamino)benzoate (961 mg, 100%).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_raw_loc = 'src-valid.txt'\n",
    "with open(valid_raw_loc, 'r', encoding='utf-8') as f:\n",
    "    valid_raw_loc = f.read().split('\\n')\n",
    "    valid_raw_loc = valid_raw_loc[:10]\n",
    "with open('tgt-valid.txt', 'r', encoding='utf-8') as f:\n",
    "    valid_raw_tgt = f.read().split('\\n')\n",
    "    valid_raw_tgt = valid_raw_tgt[:10]\n",
    "\n",
    "for cc,lin in enumerate(valid_raw_loc):\n",
    "    print(decode_sequence(lin))\n",
    "    print(valid_raw_tgt[cc])\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
